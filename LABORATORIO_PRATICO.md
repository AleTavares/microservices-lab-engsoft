# ğŸ§ª LaboratÃ³rio PrÃ¡tico: MicrosserviÃ§os E-commerce
## Guia Completo de Aprendizagem Autoguiada

---

## ğŸ“‹ **PrÃ©-requisitos e PreparaÃ§Ã£o**

### âœ… **Checklist Inicial**
- [ ] Docker e Docker Compose instalados
- [ ] Python 3.10+ instalado
- [ ] Git configurado
- [ ] Terminal/CMD disponÃ­vel
- [ ] Editor de cÃ³digo (VS Code recomendado)

### ğŸ¯ **Objetivos do LaboratÃ³rio**
Ao final deste laboratÃ³rio, vocÃª serÃ¡ capaz de:
- Executar uma arquitetura de microsserviÃ§os completa
- Entender comunicaÃ§Ã£o entre serviÃ§os
- Identificar benefÃ­cios e desafios dos microsserviÃ§os
- Implementar padrÃµes fundamentais (API Gateway, Database per Service)
- Diagnosticar e resolver problemas em sistemas distribuÃ­dos

---

## ğŸš€ **ETAPA 1: ConfiguraÃ§Ã£o Inicial (15 minutos)**

### 1.1 Preparando o Ambiente
```bash
# 1. Clone o repositÃ³rio (se ainda nÃ£o fez)
git clone https://github.com/AleTavares/microservices-lab-engsoft.git
cd microservices-lab-engsoft

# 2. Instale as dependÃªncias Python
./install-dependencies.sh

# 3. Verifique se tudo estÃ¡ funcionando
python3 --version
docker --version
docker-compose --version
```

### 1.2 Primeira ExecuÃ§Ã£o
```bash
# Inicie todos os serviÃ§os com Docker
docker-compose up --build
```

**ğŸ” O que observar:**
- [ ] 7 containers sendo criados (3 bancos + 4 serviÃ§os)
- [ ] Mensagens de "Database initialized successfully"
- [ ] Todos os serviÃ§os rodando sem erros

### 1.3 VerificaÃ§Ã£o de SaÃºde
```bash
# Em outro terminal, teste o health check
curl http://localhost:3000/api/health/all | jq '.'
```

**âœ… Resultado esperado:**
```json
{
  "gateway": "healthy",
  "services": [
    {"name": "user-service", "status": "healthy"},
    {"name": "product-service", "status": "healthy"},
    {"name": "order-service", "status": "healthy"}
  ]
}
```

---

## ğŸ” **ETAPA 2: Explorando a Arquitetura (20 minutos)**

### 2.1 Entendendo o Database per Service

**ğŸ¯ Objetivo:** Compreender como cada serviÃ§o tem seu prÃ³prio banco de dados.

```bash
# Conecte-se ao banco do User Service
./connect-db.sh user
```

**No PostgreSQL, execute:**
```sql
-- Veja a estrutura da tabela
\d users

-- Consulte os dados
SELECT * FROM users;

-- Saia do banco
\q
```

**ğŸ”„ Repita para os outros serviÃ§os:**
```bash
./connect-db.sh product
./connect-db.sh order
```

**ğŸ“ Anote suas observaÃ§Ãµes:**
- Quantas tabelas cada banco possui?
- Que dados estÃ£o armazenados em cada um?
- Como isso difere de um banco monolÃ­tico?

### 2.2 Testando ComunicaÃ§Ã£o Entre ServiÃ§os

**ğŸ¯ Objetivo:** Ver como os serviÃ§os se comunicam via HTTP.

```bash
# 1. Crie um usuÃ¡rio
curl -X POST http://localhost:3000/api/users \
  -H "Content-Type: application/json" \
  -d '{"name": "Maria Silva", "email": "maria@email.com"}'

# 2. Crie um produto
curl -X POST http://localhost:3000/api/products \
  -H "Content-Type: application/json" \
  -d '{"name": "Smartphone", "price": 1200.00, "stock": 15}'

# 3. Crie um pedido (observe a comunicaÃ§Ã£o entre serviÃ§os)
curl -X POST http://localhost:3000/api/orders \
  -H "Content-Type: application/json" \
  -d '{"userId": 1, "productId": 1, "quantity": 2}'
```

**ğŸ” Observe os logs:**
```bash
# Em outro terminal, veja os logs em tempo real
docker-compose logs -f order-service
```

**ğŸ“ QuestÃµes para reflexÃ£o:**
1. Quantas chamadas HTTP o Order Service fez?
2. O que aconteceria se o User Service estivesse offline?
3. Como vocÃª melhoraria a resiliÃªncia?

### 2.3 API Gateway em AÃ§Ã£o

**ğŸ¯ Objetivo:** Entender o papel do API Gateway.

```bash
# Acesso via Gateway (recomendado)
curl http://localhost:3000/api/users

# Acesso direto ao serviÃ§o (bypass do gateway)
curl http://localhost:3001/users
```

**ğŸ“Š Compare as respostas:**
- As respostas sÃ£o idÃªnticas?
- Que benefÃ­cios o Gateway oferece?
- Como o rate limiting funciona?

---

## ğŸ› ï¸ **ETAPA 3: ImplementaÃ§Ãµes PrÃ¡ticas (45 minutos)**

### 3.1 Adicionando um Novo Endpoint

**ğŸ¯ Objetivo:** Implementar comunicaÃ§Ã£o entre User Service e Order Service.

**ğŸ“ Tarefa:** Adicione um endpoint para listar pedidos de um usuÃ¡rio especÃ­fico.

```python
# Edite: user-service/app.py
# Adicione apÃ³s os outros endpoints:

@app.route('/users/<int:user_id>/orders', methods=['GET'])
def get_user_orders(user_id):
    try:
        # 1. Verificar se usuÃ¡rio existe
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("SELECT id, name, email FROM users WHERE id = %s", (user_id,))
        user = cur.fetchone()
        cur.close()
        conn.close()
        
        if not user:
            return jsonify({"error": "UsuÃ¡rio nÃ£o encontrado"}), 404
        
        # 2. Buscar pedidos do usuÃ¡rio no Order Service
        import requests
        ORDER_SERVICE_URL = os.environ.get('ORDER_SERVICE_URL', 'http://localhost:3003')
        
        orders_response = requests.get(f"{ORDER_SERVICE_URL}/orders", timeout=5)
        all_orders = orders_response.json()
        
        # 3. Filtrar pedidos do usuÃ¡rio
        user_orders = [order for order in all_orders if order.get('user_id') == user_id]
        
        return jsonify({
            "user": dict(user),
            "orders": user_orders,
            "total_orders": len(user_orders)
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500
```

**ğŸ§ª Teste sua implementaÃ§Ã£o:**
```bash
# Reinicie o User Service
docker-compose restart user-service

# Teste o novo endpoint
curl http://localhost:3001/users/1/orders | jq '.'
```

### 3.2 Implementando Circuit Breaker

**ğŸ¯ Objetivo:** Adicionar resiliÃªncia ao sistema.

```python
# Edite: order-service/app.py
# Adicione no inÃ­cio do arquivo:

import time

# Circuit Breaker simples
circuit_breaker = {
    "failures": 0,
    "threshold": 3,
    "timeout": 30,  # segundos
    "state": "CLOSED",  # CLOSED, OPEN, HALF_OPEN
    "last_failure": 0
}

def call_service_with_circuit_breaker(url, fallback_data=None):
    current_time = time.time()
    
    # Verificar se circuit breaker estÃ¡ aberto
    if (circuit_breaker["state"] == "OPEN" and 
        current_time - circuit_breaker["last_failure"] < circuit_breaker["timeout"]):
        print("ğŸš« Circuit breaker OPEN - usando fallback")
        return fallback_data or {"error": "Service temporarily unavailable"}
    
    # Tentar half-open se timeout passou
    if circuit_breaker["state"] == "OPEN":
        circuit_breaker["state"] = "HALF_OPEN"
    
    try:
        response = requests.get(url, timeout=5)
        response.raise_for_status()
        
        # Sucesso - resetar circuit breaker
        circuit_breaker["failures"] = 0
        circuit_breaker["state"] = "CLOSED"
        return response.json()
        
    except requests.exceptions.RequestException as e:
        circuit_breaker["failures"] += 1
        circuit_breaker["last_failure"] = current_time
        
        if circuit_breaker["failures"] >= circuit_breaker["threshold"]:
            circuit_breaker["state"] = "OPEN"
            print(f"âš ï¸ Circuit breaker OPENED after {circuit_breaker['failures']} failures")
        
        print(f"âŒ Service call failed ({circuit_breaker['failures']}/{circuit_breaker['threshold']}): {e}")
        return fallback_data or {"error": "Service call failed"}

# Substitua as chamadas requests.get() por call_service_with_circuit_breaker()
```

**ğŸ§ª Teste o Circuit Breaker:**
```bash
# 1. Pare o User Service
docker-compose stop user-service

# 2. Tente criar pedidos mÃºltiplas vezes
for i in {1..5}; do
  curl -X POST http://localhost:3000/api/orders \
    -H "Content-Type: application/json" \
    -d '{"userId": 1, "productId": 1, "quantity": 1}'
  echo "Tentativa $i"
done

# 3. Observe os logs
docker-compose logs order-service
```

### 3.3 Adicionando MÃ©tricas de Monitoramento

**ğŸ¯ Objetivo:** Implementar observabilidade bÃ¡sica.

```python
# Crie: shared/metrics.py
from datetime import datetime
import time

class MetricsCollector:
    def __init__(self):
        self.metrics = {
            "requests_total": 0,
            "errors_total": 0,
            "response_times": [],
            "endpoints": {}
        }
    
    def record_request(self, endpoint, duration, status_code):
        self.metrics["requests_total"] += 1
        self.metrics["response_times"].append(duration)
        
        if status_code >= 400:
            self.metrics["errors_total"] += 1
        
        # MÃ©tricas por endpoint
        if endpoint not in self.metrics["endpoints"]:
            self.metrics["endpoints"][endpoint] = {"count": 0, "avg_time": 0}
        
        ep_metrics = self.metrics["endpoints"][endpoint]
        ep_metrics["count"] += 1
        ep_metrics["avg_time"] = (ep_metrics["avg_time"] + duration) / 2
    
    def get_metrics(self):
        avg_response_time = (
            sum(self.metrics["response_times"]) / len(self.metrics["response_times"])
            if self.metrics["response_times"] else 0
        )
        
        error_rate = (
            (self.metrics["errors_total"] / self.metrics["requests_total"]) * 100
            if self.metrics["requests_total"] > 0 else 0
        )
        
        return {
            **self.metrics,
            "avg_response_time_ms": round(avg_response_time, 2),
            "error_rate_percent": round(error_rate, 2),
            "uptime_seconds": int(time.time() - self.start_time)
        }

# Adicione em cada serviÃ§o:
metrics_collector = MetricsCollector()
metrics_collector.start_time = time.time()

@app.before_request
def before_request():
    request.start_time = time.time()

@app.after_request
def after_request(response):
    duration = (time.time() - request.start_time) * 1000  # ms
    metrics_collector.record_request(request.endpoint, duration, response.status_code)
    return response

@app.route('/metrics', methods=['GET'])
def get_metrics():
    return jsonify(metrics_collector.get_metrics())
```

---

## ğŸ”¥ **ETAPA 4: CenÃ¡rios de Falha (25 minutos)**

### 4.1 Teste de ResiliÃªncia - Falha em Cascata

**ğŸ¯ Objetivo:** Observar como falhas se propagam em microsserviÃ§os.

```bash
# 1. Gere carga normal
for i in {1..10}; do
  curl -s http://localhost:3000/api/orders \
    -X POST \
    -H "Content-Type: application/json" \
    -d '{"userId": 1, "productId": 1, "quantity": 1}' &
done

# 2. Durante a carga, pare o Product Service
docker-compose stop product-service

# 3. Continue tentando criar pedidos
for i in {1..5}; do
  curl -X POST http://localhost:3000/api/orders \
    -H "Content-Type: application/json" \
    -d '{"userId": 1, "productId": 1, "quantity": 1}'
  echo "Tentativa pÃ³s-falha $i"
done

# 4. Reinicie o serviÃ§o
docker-compose start product-service
```

**ğŸ“ AnÃ¡lise:**
- Como o sistema se comportou durante a falha?
- Quanto tempo levou para se recuperar?
- Que melhorias vocÃª implementaria?

### 4.2 Teste de Carga - Identificando Gargalos

**ğŸ¯ Objetivo:** Encontrar limitaÃ§Ãµes de performance.

```bash
# Script de carga (salve como load_test.sh)
#!/bin/bash
echo "ğŸš€ Iniciando teste de carga..."

# FunÃ§Ã£o para fazer requisiÃ§Ãµes
make_requests() {
  for i in {1..100}; do
    curl -s http://localhost:3000/api/products > /dev/null
  done
}

# Execute mÃºltiplas instÃ¢ncias em paralelo
for i in {1..5}; do
  make_requests &
done

wait
echo "âœ… Teste de carga concluÃ­do"
```

```bash
# Execute o teste
chmod +x load_test.sh
time ./load_test.sh

# Verifique as mÃ©tricas
curl http://localhost:3002/metrics | jq '.'
```

---

## ğŸ“Š **ETAPA 5: AnÃ¡lise e OtimizaÃ§Ã£o (20 minutos)**

### 5.1 Coletando MÃ©tricas do Sistema

```bash
# Crie um script de monitoramento
cat > monitor.sh << 'EOF'
#!/bin/bash
echo "ğŸ“Š MÃ©tricas dos MicrosserviÃ§os"
echo "=============================="

services=("user-service:3001" "product-service:3002" "order-service:3003")

for service in "${services[@]}"; do
  name=$(echo $service | cut -d: -f1)
  port=$(echo $service | cut -d: -f2)
  
  echo ""
  echo "ğŸ”¹ $name:"
  curl -s http://localhost:$port/metrics | jq '{
    requests_total,
    errors_total,
    avg_response_time_ms,
    error_rate_percent
  }'
done
EOF

chmod +x monitor.sh
./monitor.sh
```

### 5.2 AnÃ¡lise de Performance

**ğŸ“ QuestÃµes para investigar:**

1. **LatÃªncia:**
   - Qual serviÃ§o tem maior tempo de resposta?
   - Como a comunicaÃ§Ã£o entre serviÃ§os afeta a latÃªncia total?

2. **Throughput:**
   - Quantas requisiÃ§Ãµes por segundo cada serviÃ§o suporta?
   - Onde estÃ£o os gargalos?

3. **Confiabilidade:**
   - Qual a taxa de erro de cada serviÃ§o?
   - Como melhorar a resiliÃªncia?

### 5.3 Propostas de Melhoria

**ğŸ¯ Baseado na sua anÃ¡lise, implemente uma das melhorias:**

**OpÃ§Ã£o A: Cache Simples**
```python
# Adicione cache em memÃ³ria no Product Service
from functools import lru_cache
import time

@lru_cache(maxsize=100)
def get_product_cached(product_id, cache_time):
    # cache_time muda a cada minuto, invalidando o cache
    return get_product_from_db(product_id)

@app.route('/products/<int:product_id>', methods=['GET'])
def get_product(product_id):
    cache_time = int(time.time() // 60)  # Cache por 1 minuto
    return get_product_cached(product_id, cache_time)
```

**OpÃ§Ã£o B: Retry com Backoff**
```python
import time
import random

def retry_with_backoff(func, max_retries=3):
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            
            wait_time = (2 ** attempt) + random.uniform(0, 1)
            print(f"Retry {attempt + 1}/{max_retries} in {wait_time:.2f}s")
            time.sleep(wait_time)
```

---

## ğŸ“ **ETAPA 6: ReflexÃ£o e PrÃ³ximos Passos (15 minutos)**

### 6.1 AutoavaliaÃ§Ã£o

**âœ… Checklist de Aprendizagem:**
- [ ] Executei com sucesso uma arquitetura de microsserviÃ§os
- [ ] Entendi como funciona o Database per Service
- [ ] Observei comunicaÃ§Ã£o sÃ­ncrona entre serviÃ§os
- [ ] Implementei um novo endpoint com comunicaÃ§Ã£o inter-serviÃ§os
- [ ] Testei cenÃ¡rios de falha e resiliÃªncia
- [ ] Coletei e analisei mÃ©tricas de performance
- [ ] Identifiquei gargalos e propus melhorias

### 6.2 QuestÃµes de ReflexÃ£o

**ğŸ“ Responda em suas prÃ³prias palavras:**

1. **Arquitetura:**
   - Quais sÃ£o as principais diferenÃ§as entre monolito e microsserviÃ§os?
   - Quando vocÃª recomendaria microsserviÃ§os vs. monolito?

2. **OperaÃ§Ãµes:**
   - Que desafios operacionais vocÃª identificou?
   - Como vocÃª resolveria o problema de debugging distribuÃ­do?

3. **Dados:**
   - Como vocÃª implementaria relatÃ³rios que precisam de dados de mÃºltiplos serviÃ§os?
   - Que estratÃ©gias usaria para manter consistÃªncia de dados?

### 6.3 PrÃ³ximos Desafios

**ğŸš€ Para continuar aprendendo:**

**NÃ­vel IntermediÃ¡rio:**
- [ ] Implementar autenticaÃ§Ã£o JWT
- [ ] Adicionar cache distribuÃ­do (Redis)
- [ ] Configurar load balancer (Nginx)
- [ ] Implementar health checks avanÃ§ados

**NÃ­vel AvanÃ§ado:**
- [ ] Event-driven architecture com message queues
- [ ] Service mesh (Istio)
- [ ] Distributed tracing (Jaeger)
- [ ] CI/CD pipeline para microsserviÃ§os

---

## ğŸ‰ **ParabÃ©ns!**

VocÃª completou com sucesso o laboratÃ³rio de microsserviÃ§os! 

**ğŸ“ˆ O que vocÃª aprendeu:**
- Arquitetura de microsserviÃ§os na prÃ¡tica
- PadrÃµes fundamentais (API Gateway, Database per Service)
- ComunicaÃ§Ã£o entre serviÃ§os
- ResiliÃªncia e tratamento de falhas
- Monitoramento e observabilidade
- AnÃ¡lise de performance

**ğŸ”„ Continue praticando:**
- Experimente com diferentes cenÃ¡rios de falha
- Implemente as melhorias sugeridas
- Explore ferramentas mais avanÃ§adas
- Aplique os conceitos em projetos reais

**Desenvolvido para Engenharia de Software** ğŸ“